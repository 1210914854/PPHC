---
title: 单机 Kong 的性能极限
taxonomy:
    category: docs
---

书接上文，如果我们真的搭建了一台拥有 25 个核心的虚拟机，并在上面安装了 Kong，它其实是无法承受五万 QPS 压力的——因为此时单机 TCP 连接数已经达到了十万以上，强如 Nginx 也顶不住的。

在经典的 HTTP 反向代理场景下，单机 Nginx 的 QPS 极限大约为一万，一旦超过这个限制，性能将不再增长甚至开始下降，用户体验也会迅速恶化。因此，我们需要对应用网关进行拆分。

### 应用网关如何拆分

从逻辑上讲，应用网关执行的是“反向代理+数据过滤”任务，并没有要求应用网关只能由一台服务器来承担。换句话说，应用网关理论上不是单点，只要多个节点的行为一致，它们就可以共同承担五万个 QPS 的真实用户流量。

我们只需要在多台机器上安装相同版本的应用网关软件，并在它们之间同步配置文件即可。Kong 采用的策略是让多个实例连接到同一个 PostgreSQL 数据库，每五秒钟从数据库获取一次最新的配置。如果数据库出现故障，那么它将保持内存中的现有配置继续运行。

Kong 集群追求的是“最终一致性”，而不是追求五秒钟的得失，这反而让系统格外地容易扩展，格外的健壮。在最后一章中，我们还将看到使用类似思维的“DNS 分布式拆分”。这种简单直接的思维颇具俄罗斯人暴力美学的典范，在后面讨论列存储 ClickHouse（俄罗斯人开发的开源列存储数据库）时还会出现。

应用网关拆分方案已经呼之欲出了——在多台应用网关前面放置一个 TCP 负载均衡器，系统架构如图 5-4 所示。

![](/media/16895753234893.jpg)
<center>图 5-4 引入负载均衡器之后的静山平台架构图</center>

### 什么是负载均衡器

负载均衡器是一种将网络流量分发到多个计算资源（例如服务器、虚拟机、容器等）进行处理的设备，图 5-4 中的 TCP 负载均衡器就是俗称的“四层负载均衡”。在云计算兴起之前，负载均衡器主要依靠硬件实现，用于将单机无法承受的大流量分散到多台物理机上共同承担。如今，软件定义网络（SDN）已经通过廉价的商用硬件颠覆了这一领域，这是我们下一章的主题，到时会详细阐述。

除了提升系统容量外，负载均衡器还具备一些高级功能：

1. 红蓝发布（Blue-Green Deployment）：这是一种发布策略，通过在两个生产环境（蓝色和绿色）之间切换来实现零停机时间部署。在部署新版本时，流量会被切换到新的环境（绿色），一旦新环境稳定运行，流量会完全切换到新环境，旧环境（蓝色）则被废弃。
2. 金丝雀发布（Canary Release）：这是一种渐进式发布策略，通过逐步将新版本的代码推向生产环境来降低风险。只有一小部分用户会看到新版本，一旦出现问题，可以迅速回滚到旧版本。
3. 根据流量特点进行灰度发布：根据用户的流量特点，将新版本的代码推送给特定的用户群体，以便在不影响整体用户体验的情况下进行测试和验证。
4. 主动调节各个后端服务器的压力：负载均衡器可以根据服务器的负载情况动态调整流量分配，以确保每个服务器的负载保持在合理范围内。
5. 屏蔽失效的后端服务器：当某个后端服务器出现故障时，负载均衡器会自动将其从流量分配中移除，确保用户的请求不会被发送到失效的服务器上。

#### 低负载下应用网关和负载均衡器可以是同一个软件

尽管应用网关和负载均衡器是两个不同的概念，但在容量不是特别大（例如不超过 1Gbps）的系统中，它们往往由同一个软件来扮演，例如 Kong 网关就同时具备这两种能力。
